{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "designed-healing",
   "metadata": {},
   "source": [
    "# Proyecto B: Calculadora de ReTweets\n",
    "### Luis Ángel de Ávila Bula - Juan Ándres Guevara\n",
    "\n",
    "En este trabajo, se buscará analizar distintos tópicos de un conjunto de tweets usando herramientas de procesamiento de lenguaje natural, tales como Word2Vec y factorización de matrices SVD, entre otras.\n",
    "\n",
    "Adicionalmente se entrenará un modelo de predicción que permitira dado un tweet, estimar cuantos retweets este tweet tendría."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-korea",
   "metadata": {},
   "source": [
    "Para esta tarea, se construye un dataset con la mayor cantidad de tweets en Colombia durante la última semana.\n",
    "\n",
    "Para ello, seleccionamos un total de 100604 tweets de la API de Twitter publicados del 15 al 21 de Febrero.\n",
    "\n",
    "Estos tweets se pueden ver plasmados en la carpeta de `data/periodX.csv` donde `X` corresponde al periodo, de 0 a 6, donde cada período es un día en la semana seleccionada.\n",
    "\n",
    "El proceso de extracción de estos tweets, se encuentran documentados más a fondo en el notebook adjunto a este, de `RecoleccionDatos.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f6468",
   "metadata": {},
   "source": [
    "Una vez con los datos extraídos, nos preparamos para procesarlos, luego importamos todas las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alternate-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import re\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "from nltk import stem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from scipy.sparse.linalg import svds as SparseSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa19e83",
   "metadata": {},
   "source": [
    "Procedemos a leer nuestros datos almacenados en el formato csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e498ebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1493736882106245120</td>\n",
       "      <td>es</td>\n",
       "      <td>@JuanCar99077589 @elojodiestro @intiasprilla Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1493736869108006912</td>\n",
       "      <td>es</td>\n",
       "      <td>@NairoQuinCo no tiene ni puta idea como es la ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1493736868755611649</td>\n",
       "      <td>es</td>\n",
       "      <td>@Enrique_GomezM  deje me  decirle con todo res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1493736858999787521</td>\n",
       "      <td>es</td>\n",
       "      <td>@PizarroMariaJo @MovimientoMAIS @UP_Colombia @...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1493736858769108992</td>\n",
       "      <td>es</td>\n",
       "      <td>Mal día para el duquecito en el parlamento eur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id lang  \\\n",
       "0  1493736882106245120   es   \n",
       "1  1493736869108006912   es   \n",
       "2  1493736868755611649   es   \n",
       "3  1493736858999787521   es   \n",
       "4  1493736858769108992   es   \n",
       "\n",
       "                                               tweet  retweet_count  \n",
       "0  @JuanCar99077589 @elojodiestro @intiasprilla Y...              0  \n",
       "1  @NairoQuinCo no tiene ni puta idea como es la ...              0  \n",
       "2  @Enrique_GomezM  deje me  decirle con todo res...              0  \n",
       "3  @PizarroMariaJo @MovimientoMAIS @UP_Colombia @...              0  \n",
       "4  Mal día para el duquecito en el parlamento eur...              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "df = pd.concat([pd.read_csv(f'data/period{i}.csv') for i in range(7)])\n",
    "df = df[[\"id\",\"lang\",\"tweet\", \"retweet_count\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6eca7",
   "metadata": {},
   "source": [
    "Leemos un archivo adicional, que son stop words en español, estas fueron tomadas de https://github.com/Alir3z4/stop-words que contiene una lista de stop words común en distintos lenguajes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6307d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/spanish_stop_words.txt',encoding='UTF-8')\n",
    "SPANISH_STOP_WORDS = file.read().split()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c4816",
   "metadata": {},
   "source": [
    "Por último antes, de seguir al análisis, definiremos nuestra rutina principal de preprocesamiento de datos, definida como se ve a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "increased-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(d):\n",
    "    # d -> document\n",
    "\n",
    "    removed = re.sub(r'http\\S+', '', d) # removes links from tweet\n",
    "    words = removed.split()\n",
    "    # Convert to lowercase every word  \n",
    "    prep = [w.lower() for w in words]\n",
    "\n",
    "    # Remove Spanish Stop Words\n",
    "    prep = [w for w in prep if w not in SPANISH_STOP_WORDS]\n",
    "    if len(prep) == 0:\n",
    "        return ''\n",
    "    # Perform Unidecode normalization for removing accentuations, special characters etc.\n",
    "    prep = [unidecode(w) for w in prep]\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    prep = [re.sub('[^A-Za-z0-9]+', '', w) for w in prep]\n",
    "    \n",
    "    # Remove empty strings\n",
    "    prep = [w for w in prep if w != '']\n",
    "    \n",
    "    # Lemmatization\n",
    "    wnl = stem.WordNetLemmatizer()        \n",
    "    prep = [wnl.lemmatize(w) for w in prep]\n",
    "    \n",
    "    \n",
    "    processed_string = ' '.join(prep)\n",
    "    return processed_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79666efe",
   "metadata": {},
   "source": [
    "Esta es bastante explicativa por si mismo, sin embargo cabe destacar algunos pasos únicos no tan usuales. Se decidio quitar por completo de los tweets todos los links con el patrón de http, y adicionalmente se hizo uso de unidecode para normalizar las palabras.\n",
    "\n",
    "Dado se esta trabajando en español, no sería deseado perder información valiosa debido a acentuaciones o similares, luego por ejemplo la palabra Bogotá, es preprocesada a bogota, sin acentuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2102fa",
   "metadata": {},
   "source": [
    "Adicionalmente definimos una rutina un poco peculiar, dado nuestro uso de stop words en español, es posible que un tweet contenga solo stop words, es decir, no nos de mucha información.\n",
    "Aunque es un caso bastante único que ocurre muy pocas veces, es bueno tenerlo presente, por eso definimos una información que nos elimine este tipo de tweets de nuestro dataset, como se ve a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395d5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_noninformant_tweets(dataset):\n",
    "    # removes those tweets that will yield empty preprocessing, this only happens when tweet is fully contained by stop words\n",
    "    # Veeeeeeery few tweets actually do this, but it's an important check to have inplace\n",
    "    indexes = []\n",
    "    for i in range(len(dataset)):\n",
    "        if preprocessing(dataset.iloc[i][\"tweet\"]) == '':\n",
    "            indexes.append(i)\n",
    "    dataset.drop(indexes, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c43bc",
   "metadata": {},
   "source": [
    "## Análisis de Tópicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389abeca",
   "metadata": {},
   "source": [
    "Primero realizaremos procesamiento sobre nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0b2d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@PizarroMariaJo @MovimientoMAIS @UP_Colombia @PoloDemocratico @petrogustavo @LevyRincon @AquinoTicias1 @Betocoralg @ColombiaHumana_ @somospactometa @PactoCol Cuantos delincuentes en un sola imagen',\n",
       " 'Mal día para el duquecito en el parlamento europeo. Le tocó quedarse calladito, creyó que ir de paseo por el mundo a nadie le iba importar lo que pasa en Colombia.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df.tweet\n",
    "tweets = [x.split() for x in tweets]\n",
    "corpus = [' '.join(tweets[i]) for i in range(len(tweets))]\n",
    "corpus[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "224b3a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizarromariajo movimientomais upcolombia polodemocratico petrogustavo levyrincon aquinoticias1 betocoralg colombiahumana somospactometa pactocol cuantos delincuentes imagen',\n",
       " 'mal dia duquecito parlamento europeo toco quedarse calladito creyo paseo mundo iba importar pasa colombia']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [preprocessing(d) for d in corpus]\n",
    "corpus[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ad7dc",
   "metadata": {},
   "source": [
    "Una vez con nuestros datos preprocesados, procedemos a hacer uso del vectorizador de TF-IDF, en el que calculamos el TF-IDF por cada par documento / vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d87be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amputado' 'amputados' 'amputo' ... 'stroke' 'strong' 'stronger']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<100604x111905 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1257986 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(corpus)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab[10000:100005])\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39875cfa",
   "metadata": {},
   "source": [
    "De esta manera para obtener los tópicos solo hace falta realizar la descomposición SVD de esta matriz, y sacar los tópicos de las matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6c7a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100604, 6) (6,) (6, 111905)\n"
     ]
    }
   ],
   "source": [
    "U, s, Vh = SparseSVD(X_tfidf)\n",
    "Vh = np.array(Vh)\n",
    "print(U.shape, s.shape, Vh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc9ba43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words = 10\n",
    "\n",
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d800d04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colombia presidente pais venezuela petro duque mundo dia seleccion gobierno',\n",
       " 'petrogustavo colombiahumana upcolombia movimientomais pizarromariajo pactocol polodemocratico somospactometa aquinoticias1 betocoralg',\n",
       " 'colombia publicar foto acaba petrogustavo bogota petro presidente venezuela pactocol',\n",
       " 'aborto 24 semana corte legal constitucional despenaliza semanas gestacion despenalizacion',\n",
       " 'colombia aborto 24 legal semana corte constitucional despenaliza pais acaba']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = 5 # Number of topics\n",
    "show_topics(Vh[:n_topics])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0a5d6",
   "metadata": {},
   "source": [
    "La factorización de valores singulares es un método para encontrar las principales dimensiones de un conjunto de datos, las dimensiones en la cual se presenta la mayor variación de los datos. La matriz $V$ nos brindó información muy interesante de nuestro conjunto de datos (una matriz tfidf). Al seleccionar las  6 filas de la matriz (tópicos) y al seleccionar las palabras más relevantes de cada una de ellas, hemos obtenido 'clusters' de palabras, que categorizan cada uno de los tweets.\n",
    "\n",
    "Con las matrices $U$, $S$ y $V$ hemos podido descomponer nuestra matriz término-documento en una matriz cuadrada documento-término ($U$), una matriz diagonal ($S$) con las importancias (varianzas) de cada término y una matriz rectangular término-documento ($V$) de donde pudimos extraer los tópicos.\n",
    "\n",
    "Los tópicos coinciden con los temas de actualidad que más relevancia están teniendo en el país. Como lo es, las próximas elecciones presidenciales y de congreso, la actividad las redes de Gustavo Petro, los discursos del presidente Duque, la legalización del aborto, etc. Esto nos demuestra que el análisis de tópicos nos puede brindar un muy buen contexto, acerca de lo que tratan cada uno de los documentos de una manera muy sencilla y sin la necesidad de conocer el contenido de cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f6cc04",
   "metadata": {},
   "source": [
    "## Predicción de Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bf6ab",
   "metadata": {},
   "source": [
    "Ahora nuestro objetivo es poder predecir el número de retweets según un día dado.\n",
    "Es decir, dado un tweet cuantos retweets se podría esperar que este tuviera. Asimismo, como realizar un análisis sobre cuales palabras, son las que están produciendo más retweets, según el día y claramente la tendencia.\n",
    "\n",
    "Para esto construimos un Pipeline a seguir por cada día (conjunto de tweets).\n",
    "Se hará uso de la técnica de Word2Vec, para transformar todos los tweets de un día, a un espacio embebido de vectores, y luego ajustar un regresor de Random Forest a los datos, para así dado un nuevo vector (tweet) predecir cuantos retweets se podría esperar que este va a tener.\n",
    "\n",
    "Solamente existen dos detalles controversiales a esta técnica, los cuales veremos a continuación:\n",
    "\n",
    "Primero, Word2Vec realiza embebimientos sobre palabras, no sobre oraciones, como tweets.\n",
    "Para esto debemos determinar una manera de asignarle a un tweet a un solo vector que sea representativo, para esto se decide usar el promedio de los vectores correspondientes a cada palabra del tweet, como se ve a continuación:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77942213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_tweet(model, tweet):\n",
    "    vectorized_tweet = []\n",
    "    for word in tweet:\n",
    "        vectorized_tweet.append(model.wv.get_vector(word))\n",
    "    return np.average(vectorized_tweet,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697180e",
   "metadata": {},
   "source": [
    "Segundo, Word2Vec es un embebimiento para un conjunto dado de palabras. Si buscamos realizar una predicción sobre cualquier otro tweet que contenga una palabra desconocida al modelo, no podremos realizar la predicción. \n",
    "\n",
    "Afortunadamente, la librería Gensim permite actualizar el modelo de Word2Vec con nuevos vocabularios y reentrenarlos de manera eficiente. Por lo cual, cuando se presente una nueva palabra al modelo, solamente hace falta actualizar el modelo existente para incluirla.\n",
    "\n",
    "Esto lo podemos hacer a través de las siguientes funciones que verifican que las palabras existan en el modelo, y si no es así, lo actualiza acordemente.\n",
    "Una función es para un solo tweet, y otra es para multiples, por términos de simplicidad y eficiencia al actualizar el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59903f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewTweetVector(model, tweet): # Intented for a single tweet \n",
    "  tweet = preprocessing(tweet)\n",
    "  words = tweet.split(' ')\n",
    "  missing_words = [x for x in words if x not in model.wv.key_to_index]\n",
    "  if len(missing_words) > 0:\n",
    "    ## adding a word to the model\n",
    "    model.build_vocab([missing_words], update=True)\n",
    "    model.train([missing_words], total_examples=model.corpus_count, epochs=model.epochs)\n",
    "  return vectorized_tweet(model, words)\n",
    "\n",
    "def getNewTweetVectorsMultiple(model, tweets): # Intended for a multiple list of tweets, for more efficiency\n",
    "    list_of_tweets = [preprocessing(tw) for tw in tweets]\n",
    "    list_of_words = [tw.split(' ') for tw in list_of_tweets]\n",
    "    new_sentences = [] # only add sentences which aren't already in the model.\n",
    "    for sentence in list_of_words:\n",
    "        for word in sentence:\n",
    "          if word not in model.wv.key_to_index:\n",
    "            new_sentences.append(sentence)\n",
    "            break \n",
    "    \n",
    "    if len(new_sentences) > 0:\n",
    "        print(f\"Adding {len(new_sentences)} new sentences to model\")\n",
    "        ## add new sentences to model\n",
    "        model.build_vocab(new_sentences, update=True)\n",
    "        model.train(new_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    # get vectorized tweets with our newly updated model\n",
    "    return np.row_stack([vectorized_tweet(model, x) for x in list_of_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b792fdb",
   "metadata": {},
   "source": [
    "Con esos detalles solucionados, solo hace falta diseñar nuestro pipeline de procesamiento, como fue descrito anteriormente.\n",
    "Dado un corpus (conjunto de tweets), y un y, el número de retweets de cada tweet correspondiente.\n",
    "\n",
    "Se realiza preprocesamiento de los tweets, crea un modelo word2vec, y posteriormente se entrena con un regresor de Random Forest, como lo vemos a continuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98bebf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildAndTrainModel(corpus, y, vector_size=500, min_count = 1, workers = 20, sg=1, window = 30, sample = 1e-6, random_forest_depth = 3, random_seed = 42):\n",
    "    '''Receives Corpus and y\n",
    "    Corpus is a list of documents. In this context a list of tweets\n",
    "    Y is the regression target for the given document. In this context, the number of retweets.\n",
    "    INCLUDES PREPROCESSING\n",
    "    Builds a word2vec model with given parameters, and then creates and trains Random Forest Regressor\n",
    "\n",
    "    Returns: The trained word2vec model, and the fitted random forest regressor'''\n",
    "    prep = [preprocessing(d) for d in corpus]\n",
    "    \n",
    "    sentences = []\n",
    "    for document in prep:\n",
    "        sentences.append(document.split())\n",
    "    model = Word2Vec(sentences=sentences, vector_size=vector_size, window=window, min_count=min_count, workers=workers, sg=sg, sample=sample,\n",
    "            seed=random_seed)\n",
    "\n",
    "    X = np.row_stack([vectorized_tweet(model, x) for x in sentences])\n",
    "    regr = RandomForestRegressor(max_depth = random_forest_depth, random_state = random_seed, n_jobs=-1)\n",
    "    regr.fit(X,y)\n",
    "    return model, regr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d486a",
   "metadata": {},
   "source": [
    "Por último haremos pruebas sobre estos modelos, y es necesario determinar que tan buenos son, para esto usaremos la medida de RMSE (Root Mean Squared Error), la cual calcularemos con la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aad58508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModelRMSE(model, regr, test_tweets, y_test):\n",
    "    X_test = getNewTweetVectorsMultiple(model, test_tweets)\n",
    "    y_predicted = regr.predict(X_test)\n",
    "    return mean_squared_error(y_test, y_predicted, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1d433",
   "metadata": {},
   "source": [
    "Ahora pongamos a prueba nuestros modelos diseñados, todos los hiperpárametros fueron seleccionados *empiricamente*. \n",
    "\n",
    "Por cada conjunto de tweets de cada día, desde febrero 15 hasta febrero 21 (inclusivo), se realiza una separación de conjunto de datos de prueba, y datos de entrenamiento.\n",
    "\n",
    "Un 80% de los tweets son tomados para entrenar y el 20% restante para probar que tan bien se desarrolla el modelo ante nuevos datos.\n",
    "Cabe destacar, que esta separación se realiza previamente a cualquier procesamiento sobre los datos, para asegurar que sea totalmente imparcial ante los datos nuevos. \n",
    "\n",
    "Es decir, una vez entrenado el modelo, para predecir sobre los datos de prueba, es necesario realizar preprocesamiento sobre ellos, añadirlos al modelo de Word2Vec, actualizar el modelo, y luego realizar la predicción con el regresor de Random Forest. Justo como se realizaría con un tweet totalmente nuevo.\n",
    "\n",
    "De esta manera, se realiza el pipeline y se calcula el RMSE como medida de error, y luego se calcula el promedio total de estos, a través de los 7 días.\n",
    "\n",
    "Cabe destacar que este proceso puede ser un poco demorado, dependiendo del procesador de la maquina puede tomar entre 2-10m, los resultados estarán plasmados en una tabla inferior.\n",
    "\n",
    "Esto lo podemos ver a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb763d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 1832 new sentences to model\n",
      "Tweets from Feb 15 - Feb 16(2022) RMSE =  109.92081235828661\n",
      "Adding 1798 new sentences to model\n",
      "Tweets from Feb 16 - Feb 17(2022) RMSE =  68.24988670391909\n",
      "Adding 1847 new sentences to model\n",
      "Tweets from Feb 17 - Feb 18(2022) RMSE =  49.422624497886424\n",
      "Adding 1830 new sentences to model\n",
      "Tweets from Feb 18 - Feb 19(2022) RMSE =  38.48191579663727\n",
      "Adding 1844 new sentences to model\n",
      "Tweets from Feb 19 - Feb 20(2022) RMSE =  51.37659100685054\n",
      "Adding 1812 new sentences to model\n",
      "Tweets from Feb 20 - Feb 21(2022) RMSE =  30.704698178423232\n",
      "Adding 1469 new sentences to model\n",
      "Tweets from Feb 21 - Feb 22(2022) RMSE =  64.14250785694945\n",
      "Total Average RMSE across all 7 days: 58.89986234270753:\n"
     ]
    }
   ],
   "source": [
    "avg_rmse = 0\n",
    "for i in range(7):\n",
    "  day_df = pd.read_csv(f'data/period{i}.csv')\n",
    "  clean_noninformant_tweets(day_df)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(day_df[\"tweet\"], day_df[\"retweet_count\"], test_size=0.2, random_state=42)\n",
    "  model, regr = BuildAndTrainModel(X_train,y_train, vector_size=350, min_count = 1, workers = 1, sg=1, window = 10, \n",
    "                                  sample = 1e-3, random_forest_depth = 2, random_seed=42)\n",
    "  rmse = TestModelRMSE(model, regr, X_test, y_test)\n",
    "  avg_rmse += rmse\n",
    "  print(f\"Tweets from Feb {15 + i} - Feb {15 + i + 1}(2022) RMSE = \", TestModelRMSE(model, regr, X_test, y_test))\n",
    "avg_rmse /= 7\n",
    "print(f\"Total Average RMSE across all 7 days: {avg_rmse}:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a01de",
   "metadata": {},
   "source": [
    "| Day | RMSE |\n",
    "| --- | --- | \n",
    "| Feb 15 | 109.9208 |\n",
    "| Feb 16 | 68.2498 | \n",
    "| Feb 17 | 49.4226 | \n",
    "| Feb 18 | 38.4819 | \n",
    "| Feb 19 | 51.3765 | \n",
    "| Feb 20 | 30.7659 | \n",
    "| Feb 21 | 64.14250 | \n",
    "| Average | 58.8998 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30fbe90",
   "metadata": {},
   "source": [
    "Cabe destacar que representa el error promedio, dado en las unidades originales. Es decir, se puede interpretar en unidades como retweets.\n",
    "\n",
    "Así, en promedio, nuestras predicciones tienen un error de alrededor de 59 retweets. Lo cual nos da una idea *decente* de cómo funciona nuestro modelo.\n",
    "\n",
    "Twitter es muy variado, y los retweets tienden a ser muy dispersos, con muchos retweets teniendo casi que 0 a 5,10 retweets y no más, y con muchos datos atípicos que algunos tweets explotan y tienen 15 mil o 20 mil retweets.\n",
    "\n",
    "¡Al considerar nuestro error para un tweet que alcanza miles de retweets, el error se podría considerar muy bueno!\n",
    "Si obtengo más de 2mil retweets un error de 50 no afecta mucho.\n",
    "\n",
    "Mientras que, en el otro lado, se podría considerar que un si se predice que un tweet va tener 5 retweets, el error de 58 retweets es gigantesco.\n",
    "\n",
    "Esto se debe a que nuestro modelo es basado en palabras, frecuencias y oraciones, no va más allá y no considera detalles como el orden, usuarios conexiones entre muchos otros factores complejos que podrían determinar realmente la cantidad de retweets.\n",
    "\n",
    "Por ejemplo, a modo de ilustración, sí un nuevo usuario de la plataforma pública exactamente el mismo tweet que el presidente, es (bastante) probable que el tweet del presidente reciba mayor retweets, que el del nuevo usuario. Este tipo de ocurrencias confunde a nuestro modelo, ya que no es capaz de determinar si el tweet públicado se debería asociar a una alta o baja cantidad de retweets.\n",
    "\n",
    "Pero no todo es tan malo! Nos puede ayudar a analizar ciertas tendencias del día como lo veremos a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77afcfe",
   "metadata": {},
   "source": [
    "### Palabras que Maximizan los Retweets\n",
    "\n",
    "Un beneficio de que nuestro modelo este construido en base de palabras es que es fácil predecir por cada palabra su salida y así determinar aquellas palabras que más se asocian al retweeteo.\n",
    "\n",
    "Esto se podría interpretar como aquellos tweets que estén más cerca a estas palabras en el espacio embebido, son más probables de obtener retweets.\n",
    "\n",
    "Podría significar palabras controversiales del día o sencillamente que fueron retweeatadas muchas veces, pero en algunas ocasiones nos dan un *insight* de las tendencias del día. \n",
    "\n",
    "Para esto, tomamos nuestro modelo y regresor entrenado, y por cada palabra del modelo le obtenemos su predicción, luego las organizamos de mayor a menor para ver las de mayor valor de retweeteo.\n",
    "\n",
    "En este caso, para mejorar nuestros modelos lo entrenaremos una vez más, pero esta vez con todo el conjunto de datos de cada día.\n",
    "Adicionalmente, la mayoría se encuentra pre-entrenado y almacenado en los datos, para que este proceso no tome mucho tiempo:\n",
    "(Dado el límite de 500mb, se tuvieron que recortar dos modelos ya entrenados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4492c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Train and Store\n",
    "# for i in range(7):\n",
    "#   day_df = pd.read_csv(f'data/period{i}.csv')\n",
    "#   clean_noninformant_tweets(day_df)\n",
    "#   model, regr = BuildAndTrainModel(day_df[\"tweet\"], day_df[\"retweet_count\"], vector_size=350, min_count = 1, workers = 1, sg=1, window = 10, \n",
    "#                                   sample = 1e-3, random_forest_depth = 2, random_seed=42)\n",
    "#   dump((model, regr), f'data/trained_model_{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876e635",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56974cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0, regr0 = load('data/trained_model_0')\n",
    "model1, regr1 = load('data/trained_model_1')\n",
    "model2, regr2 = load('data/trained_model_2')\n",
    "model3, regr3 = load('data/trained_model_3')\n",
    "model4, regr4 = load('data/trained_model_4')\n",
    "model5, regr5 = load('data/trained_model_5')\n",
    "model6, regr6 = load('data/trained_model_6')\n",
    "models = [model0, model1, model2, model3, model4, model5, model6]\n",
    "regressors = [regr0, regr1, regr2 ,regr3, regr4 , regr5, regr6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787f121",
   "metadata": {},
   "source": [
    "Definimos una función que nos ayudara a mostrar los datos *side_by_side*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14cbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "### Taken and adapted from https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side\n",
    "def display_side_by_side(dfs:list, captions:list):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        try:\n",
    "            output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption).hide()._repr_html_()\n",
    "        except:\n",
    "            output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d631609",
   "metadata": {},
   "source": [
    "Realizamos la predicción para todas las palabras de cada modelo, y tomamos las top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd905e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10df = []\n",
    "for model, regr in zip(models, regressors):\n",
    "  words2retweet = pd.DataFrame(columns = [\"words\", \"retweet_value\"])\n",
    "  words2retweet[\"words\"] = model.wv.index_to_key\n",
    "  words2retweet[\"retweet_value\"] = regr.predict(model.wv.vectors)\n",
    "  df = words2retweet.sort_values(by=['retweet_value'], ascending=False)[:20]\n",
    "  top10df.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d500d6",
   "metadata": {},
   "source": [
    "Las mostramos de forma amigable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc471c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4579e_\" style='display:inline'>\n",
       "  <caption>Feb 15</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >words</th>\n",
       "      <th class=\"col_heading level0 col1\" >retweet_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row0\" class=\"row_heading level0 row0\" >135</th>\n",
       "      <td id=\"T_4579e_row0_col0\" class=\"data row0 col0\" >parlamento</td>\n",
       "      <td id=\"T_4579e_row0_col1\" class=\"data row0 col1\" >3829.248177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row1\" class=\"row_heading level0 row1\" >2551</th>\n",
       "      <td id=\"T_4579e_row1_col0\" class=\"data row1 col0\" >apreciaciones</td>\n",
       "      <td id=\"T_4579e_row1_col1\" class=\"data row1 col1\" >3728.793554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row2\" class=\"row_heading level0 row2\" >150</th>\n",
       "      <td id=\"T_4579e_row2_col0\" class=\"data row2 col0\" >europarles</td>\n",
       "      <td id=\"T_4579e_row2_col1\" class=\"data row2 col1\" >3500.677164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row3\" class=\"row_heading level0 row3\" >1808</th>\n",
       "      <td id=\"T_4579e_row3_col0\" class=\"data row3 col0\" >reclama</td>\n",
       "      <td id=\"T_4579e_row3_col1\" class=\"data row3 col1\" >3494.457406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row4\" class=\"row_heading level0 row4\" >2816</th>\n",
       "      <td id=\"T_4579e_row4_col0\" class=\"data row4 col0\" >erroneas</td>\n",
       "      <td id=\"T_4579e_row4_col1\" class=\"data row4 col1\" >3490.845204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row5\" class=\"row_heading level0 row5\" >191</th>\n",
       "      <td id=\"T_4579e_row5_col0\" class=\"data row5 col0\" >europeo</td>\n",
       "      <td id=\"T_4579e_row5_col1\" class=\"data row5 col1\" >3356.019245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row6\" class=\"row_heading level0 row6\" >194</th>\n",
       "      <td id=\"T_4579e_row6_col0\" class=\"data row6 col0\" >lideres</td>\n",
       "      <td id=\"T_4579e_row6_col1\" class=\"data row6 col1\" >3277.079741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row7\" class=\"row_heading level0 row7\" >761</th>\n",
       "      <td id=\"T_4579e_row7_col0\" class=\"data row7 col0\" >europea</td>\n",
       "      <td id=\"T_4579e_row7_col1\" class=\"data row7 col1\" >3190.184071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row8\" class=\"row_heading level0 row8\" >279</th>\n",
       "      <td id=\"T_4579e_row8_col0\" class=\"data row8 col0\" >eurodiputados</td>\n",
       "      <td id=\"T_4579e_row8_col1\" class=\"data row8 col1\" >3118.198776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row9\" class=\"row_heading level0 row9\" >17</th>\n",
       "      <td id=\"T_4579e_row9_col0\" class=\"data row9 col0\" >ivanduque</td>\n",
       "      <td id=\"T_4579e_row9_col1\" class=\"data row9 col1\" >3105.976882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row10\" class=\"row_heading level0 row10\" >670</th>\n",
       "      <td id=\"T_4579e_row10_col0\" class=\"data row10 col0\" >masacres</td>\n",
       "      <td id=\"T_4579e_row10_col1\" class=\"data row10 col1\" >3023.668618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row11\" class=\"row_heading level0 row11\" >1144</th>\n",
       "      <td id=\"T_4579e_row11_col0\" class=\"data row11 col0\" >acuerdos</td>\n",
       "      <td id=\"T_4579e_row11_col1\" class=\"data row11 col1\" >2956.193352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row12\" class=\"row_heading level0 row12\" >407</th>\n",
       "      <td id=\"T_4579e_row12_col0\" class=\"data row12 col0\" >intervencion</td>\n",
       "      <td id=\"T_4579e_row12_col1\" class=\"data row12 col1\" >2880.800682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row13\" class=\"row_heading level0 row13\" >754</th>\n",
       "      <td id=\"T_4579e_row13_col0\" class=\"data row13 col0\" >nombres</td>\n",
       "      <td id=\"T_4579e_row13_col1\" class=\"data row13 col1\" >2877.650450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row14\" class=\"row_heading level0 row14\" >1221</th>\n",
       "      <td id=\"T_4579e_row14_col0\" class=\"data row14 col0\" >matanza</td>\n",
       "      <td id=\"T_4579e_row14_col1\" class=\"data row14 col1\" >2877.270191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row15\" class=\"row_heading level0 row15\" >475</th>\n",
       "      <td id=\"T_4579e_row15_col0\" class=\"data row15 col0\" >asesinados</td>\n",
       "      <td id=\"T_4579e_row15_col1\" class=\"data row15 col1\" >2875.112946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row16\" class=\"row_heading level0 row16\" >1381</th>\n",
       "      <td id=\"T_4579e_row16_col0\" class=\"data row16 col0\" >paren</td>\n",
       "      <td id=\"T_4579e_row16_col1\" class=\"data row16 col1\" >2798.092656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row17\" class=\"row_heading level0 row17\" >2335</th>\n",
       "      <td id=\"T_4579e_row17_col0\" class=\"data row17 col0\" >portaron</td>\n",
       "      <td id=\"T_4579e_row17_col1\" class=\"data row17 col1\" >2718.899182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row18\" class=\"row_heading level0 row18\" >1406</th>\n",
       "      <td id=\"T_4579e_row18_col0\" class=\"data row18 col0\" >mensajes</td>\n",
       "      <td id=\"T_4579e_row18_col1\" class=\"data row18 col1\" >2561.165865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4579e_level0_row19\" class=\"row_heading level0 row19\" >299</th>\n",
       "      <td id=\"T_4579e_row19_col0\" class=\"data row19 col0\" >union</td>\n",
       "      <td id=\"T_4579e_row19_col1\" class=\"data row19 col1\" >2545.814569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "   <style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5a07a_\" style='display:inline'>\n",
       "  <caption>Feb 16</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >words</th>\n",
       "      <th class=\"col_heading level0 col1\" >retweet_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row0\" class=\"row_heading level0 row0\" >1325</th>\n",
       "      <td id=\"T_5a07a_row0_col0\" class=\"data row0 col0\" >abogado</td>\n",
       "      <td id=\"T_5a07a_row0_col1\" class=\"data row0 col1\" >922.334754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row1\" class=\"row_heading level0 row1\" >25</th>\n",
       "      <td id=\"T_5a07a_row1_col0\" class=\"data row1 col0\" >paises</td>\n",
       "      <td id=\"T_5a07a_row1_col1\" class=\"data row1 col1\" >906.567769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row2\" class=\"row_heading level0 row2\" >91</th>\n",
       "      <td id=\"T_5a07a_row2_col0\" class=\"data row2 col0\" >millones</td>\n",
       "      <td id=\"T_5a07a_row2_col1\" class=\"data row2 col1\" >856.073468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row3\" class=\"row_heading level0 row3\" >82</th>\n",
       "      <td id=\"T_5a07a_row3_col0\" class=\"data row3 col0\" >10</td>\n",
       "      <td id=\"T_5a07a_row3_col1\" class=\"data row3 col1\" >811.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row4\" class=\"row_heading level0 row4\" >535</th>\n",
       "      <td id=\"T_5a07a_row4_col0\" class=\"data row4 col0\" >llevo</td>\n",
       "      <td id=\"T_5a07a_row4_col1\" class=\"data row4 col1\" >793.032786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row5\" class=\"row_heading level0 row5\" >1678</th>\n",
       "      <td id=\"T_5a07a_row5_col0\" class=\"data row5 col0\" >2016</td>\n",
       "      <td id=\"T_5a07a_row5_col1\" class=\"data row5 col1\" >761.480690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row6\" class=\"row_heading level0 row6\" >258</th>\n",
       "      <td id=\"T_5a07a_row6_col0\" class=\"data row6 col0\" >8</td>\n",
       "      <td id=\"T_5a07a_row6_col1\" class=\"data row6 col1\" >682.850989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row7\" class=\"row_heading level0 row7\" >368</th>\n",
       "      <td id=\"T_5a07a_row7_col0\" class=\"data row7 col0\" >9</td>\n",
       "      <td id=\"T_5a07a_row7_col1\" class=\"data row7 col1\" >601.767222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row8\" class=\"row_heading level0 row8\" >295</th>\n",
       "      <td id=\"T_5a07a_row8_col0\" class=\"data row8 col0\" >lugares</td>\n",
       "      <td id=\"T_5a07a_row8_col1\" class=\"data row8 col1\" >557.995827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row9\" class=\"row_heading level0 row9\" >49</th>\n",
       "      <td id=\"T_5a07a_row9_col0\" class=\"data row9 col0\" >nacional</td>\n",
       "      <td id=\"T_5a07a_row9_col1\" class=\"data row9 col1\" >510.868975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row10\" class=\"row_heading level0 row10\" >256</th>\n",
       "      <td id=\"T_5a07a_row10_col0\" class=\"data row10 col0\" >conoce</td>\n",
       "      <td id=\"T_5a07a_row10_col1\" class=\"data row10 col1\" >505.684048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row11\" class=\"row_heading level0 row11\" >342</th>\n",
       "      <td id=\"T_5a07a_row11_col0\" class=\"data row11 col0\" >familia</td>\n",
       "      <td id=\"T_5a07a_row11_col1\" class=\"data row11 col1\" >505.684048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row12\" class=\"row_heading level0 row12\" >593</th>\n",
       "      <td id=\"T_5a07a_row12_col0\" class=\"data row12 col0\" >uruguay</td>\n",
       "      <td id=\"T_5a07a_row12_col1\" class=\"data row12 col1\" >505.148722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row13\" class=\"row_heading level0 row13\" >751</th>\n",
       "      <td id=\"T_5a07a_row13_col0\" class=\"data row13 col0\" >paraguay</td>\n",
       "      <td id=\"T_5a07a_row13_col1\" class=\"data row13 col1\" >445.771903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row14\" class=\"row_heading level0 row14\" >796</th>\n",
       "      <td id=\"T_5a07a_row14_col0\" class=\"data row14 col0\" >momento</td>\n",
       "      <td id=\"T_5a07a_row14_col1\" class=\"data row14 col1\" >438.335363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row15\" class=\"row_heading level0 row15\" >1329</th>\n",
       "      <td id=\"T_5a07a_row15_col0\" class=\"data row15 col0\" >agosto</td>\n",
       "      <td id=\"T_5a07a_row15_col1\" class=\"data row15 col1\" >436.495212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row16\" class=\"row_heading level0 row16\" >2583</th>\n",
       "      <td id=\"T_5a07a_row16_col0\" class=\"data row16 col0\" >junio</td>\n",
       "      <td id=\"T_5a07a_row16_col1\" class=\"data row16 col1\" >394.734394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row17\" class=\"row_heading level0 row17\" >125</th>\n",
       "      <td id=\"T_5a07a_row17_col0\" class=\"data row17 col0\" >realidad</td>\n",
       "      <td id=\"T_5a07a_row17_col1\" class=\"data row17 col1\" >391.947800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row18\" class=\"row_heading level0 row18\" >2454</th>\n",
       "      <td id=\"T_5a07a_row18_col0\" class=\"data row18 col0\" >goodman</td>\n",
       "      <td id=\"T_5a07a_row18_col1\" class=\"data row18 col1\" >386.129388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a07a_level0_row19\" class=\"row_heading level0 row19\" >61</th>\n",
       "      <td id=\"T_5a07a_row19_col0\" class=\"data row19 col0\" >2</td>\n",
       "      <td id=\"T_5a07a_row19_col1\" class=\"data row19 col1\" >360.906769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "   <style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_635e8_\" style='display:inline'>\n",
       "  <caption>Feb 17</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >words</th>\n",
       "      <th class=\"col_heading level0 col1\" >retweet_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row0\" class=\"row_heading level0 row0\" >125</th>\n",
       "      <td id=\"T_635e8_row0_col0\" class=\"data row0 col0\" >candidato</td>\n",
       "      <td id=\"T_635e8_row0_col1\" class=\"data row0 col1\" >225.864299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row1\" class=\"row_heading level0 row1\" >434</th>\n",
       "      <td id=\"T_635e8_row1_col0\" class=\"data row1 col0\" >camara</td>\n",
       "      <td id=\"T_635e8_row1_col1\" class=\"data row1 col1\" >223.556830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row2\" class=\"row_heading level0 row2\" >94</th>\n",
       "      <td id=\"T_635e8_row2_col0\" class=\"data row2 col0\" >partido</td>\n",
       "      <td id=\"T_635e8_row2_col1\" class=\"data row2 col1\" >208.687957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row3\" class=\"row_heading level0 row3\" >107</th>\n",
       "      <td id=\"T_635e8_row3_col0\" class=\"data row3 col0\" >gustavo</td>\n",
       "      <td id=\"T_635e8_row3_col1\" class=\"data row3 col1\" >168.713932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row4\" class=\"row_heading level0 row4\" >53</th>\n",
       "      <td id=\"T_635e8_row4_col0\" class=\"data row4 col0\" >cambio</td>\n",
       "      <td id=\"T_635e8_row4_col1\" class=\"data row4 col1\" >166.047399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row5\" class=\"row_heading level0 row5\" >113</th>\n",
       "      <td id=\"T_635e8_row5_col0\" class=\"data row5 col0\" >historico</td>\n",
       "      <td id=\"T_635e8_row5_col1\" class=\"data row5 col1\" >164.870344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row6\" class=\"row_heading level0 row6\" >83</th>\n",
       "      <td id=\"T_635e8_row6_col0\" class=\"data row6 col0\" >pacto</td>\n",
       "      <td id=\"T_635e8_row6_col1\" class=\"data row6 col1\" >163.844151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row7\" class=\"row_heading level0 row7\" >51</th>\n",
       "      <td id=\"T_635e8_row7_col0\" class=\"data row7 col0\" >politico</td>\n",
       "      <td id=\"T_635e8_row7_col1\" class=\"data row7 col1\" >149.906407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row8\" class=\"row_heading level0 row8\" >399</th>\n",
       "      <td id=\"T_635e8_row8_col0\" class=\"data row8 col0\" >consulta</td>\n",
       "      <td id=\"T_635e8_row8_col1\" class=\"data row8 col1\" >145.383915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row9\" class=\"row_heading level0 row9\" >492</th>\n",
       "      <td id=\"T_635e8_row9_col0\" class=\"data row9 col0\" >justa</td>\n",
       "      <td id=\"T_635e8_row9_col1\" class=\"data row9 col1\" >145.118102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row10\" class=\"row_heading level0 row10\" >100</th>\n",
       "      <td id=\"T_635e8_row10_col0\" class=\"data row10 col0\" >congreso</td>\n",
       "      <td id=\"T_635e8_row10_col1\" class=\"data row10 col1\" >136.060992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row11\" class=\"row_heading level0 row11\" >357</th>\n",
       "      <td id=\"T_635e8_row11_col0\" class=\"data row11 col0\" >aydeelizarazoc</td>\n",
       "      <td id=\"T_635e8_row11_col1\" class=\"data row11 col1\" >132.649965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row12\" class=\"row_heading level0 row12\" >139</th>\n",
       "      <td id=\"T_635e8_row12_col0\" class=\"data row12 col0\" >libre</td>\n",
       "      <td id=\"T_635e8_row12_col1\" class=\"data row12 col1\" >131.022827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row13\" class=\"row_heading level0 row13\" >264</th>\n",
       "      <td id=\"T_635e8_row13_col0\" class=\"data row13 col0\" >voto</td>\n",
       "      <td id=\"T_635e8_row13_col1\" class=\"data row13 col1\" >126.337174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row14\" class=\"row_heading level0 row14\" >143</th>\n",
       "      <td id=\"T_635e8_row14_col0\" class=\"data row14 col0\" >centro</td>\n",
       "      <td id=\"T_635e8_row14_col1\" class=\"data row14 col1\" >126.262056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row15\" class=\"row_heading level0 row15\" >695</th>\n",
       "      <td id=\"T_635e8_row15_col0\" class=\"data row15 col0\" >libres</td>\n",
       "      <td id=\"T_635e8_row15_col1\" class=\"data row15 col1\" >126.215271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row16\" class=\"row_heading level0 row16\" >196</th>\n",
       "      <td id=\"T_635e8_row16_col0\" class=\"data row16 col0\" >marzo</td>\n",
       "      <td id=\"T_635e8_row16_col1\" class=\"data row16 col1\" >125.577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row17\" class=\"row_heading level0 row17\" >582</th>\n",
       "      <td id=\"T_635e8_row17_col0\" class=\"data row17 col0\" >valle</td>\n",
       "      <td id=\"T_635e8_row17_col1\" class=\"data row17 col1\" >118.613449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row18\" class=\"row_heading level0 row18\" >279</th>\n",
       "      <td id=\"T_635e8_row18_col0\" class=\"data row18 col0\" >pactohistorico</td>\n",
       "      <td id=\"T_635e8_row18_col1\" class=\"data row18 col1\" >110.979424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_635e8_level0_row19\" class=\"row_heading level0 row19\" >284</th>\n",
       "      <td id=\"T_635e8_row19_col0\" class=\"data row19 col0\" >necesitamosque</td>\n",
       "      <td id=\"T_635e8_row19_col1\" class=\"data row19 col1\" >106.753151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "   <style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4854a_\" style='display:inline'>\n",
       "  <caption>Feb 18</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >words</th>\n",
       "      <th class=\"col_heading level0 col1\" >retweet_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row0\" class=\"row_heading level0 row0\" >43</th>\n",
       "      <td id=\"T_4854a_row0_col0\" class=\"data row0 col0\" >duque</td>\n",
       "      <td id=\"T_4854a_row0_col1\" class=\"data row0 col1\" >976.012237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row1\" class=\"row_heading level0 row1\" >163</th>\n",
       "      <td id=\"T_4854a_row1_col0\" class=\"data row1 col0\" >ivan</td>\n",
       "      <td id=\"T_4854a_row1_col1\" class=\"data row1 col1\" >975.718936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row2\" class=\"row_heading level0 row2\" >88</th>\n",
       "      <td id=\"T_4854a_row2_col0\" class=\"data row2 col0\" >el</td>\n",
       "      <td id=\"T_4854a_row2_col1\" class=\"data row2 col1\" >870.237196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row3\" class=\"row_heading level0 row3\" >567</th>\n",
       "      <td id=\"T_4854a_row3_col0\" class=\"data row3 col0\" >pide</td>\n",
       "      <td id=\"T_4854a_row3_col1\" class=\"data row3 col1\" >799.746836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row4\" class=\"row_heading level0 row4\" >664</th>\n",
       "      <td id=\"T_4854a_row4_col0\" class=\"data row4 col0\" >guaido</td>\n",
       "      <td id=\"T_4854a_row4_col1\" class=\"data row4 col1\" >682.468663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row5\" class=\"row_heading level0 row5\" >10</th>\n",
       "      <td id=\"T_4854a_row5_col0\" class=\"data row5 col0\" >gobierno</td>\n",
       "      <td id=\"T_4854a_row5_col1\" class=\"data row5 col1\" >645.703406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row6\" class=\"row_heading level0 row6\" >661</th>\n",
       "      <td id=\"T_4854a_row6_col0\" class=\"data row6 col0\" >merlano</td>\n",
       "      <td id=\"T_4854a_row6_col1\" class=\"data row6 col1\" >593.991040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row7\" class=\"row_heading level0 row7\" >392</th>\n",
       "      <td id=\"T_4854a_row7_col0\" class=\"data row7 col0\" >carlos</td>\n",
       "      <td id=\"T_4854a_row7_col1\" class=\"data row7 col1\" >555.465849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row8\" class=\"row_heading level0 row8\" >7</th>\n",
       "      <td id=\"T_4854a_row8_col0\" class=\"data row8 col0\" >venezuela</td>\n",
       "      <td id=\"T_4854a_row8_col1\" class=\"data row8 col1\" >470.726312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row9\" class=\"row_heading level0 row9\" >955</th>\n",
       "      <td id=\"T_4854a_row9_col0\" class=\"data row9 col0\" >bandas</td>\n",
       "      <td id=\"T_4854a_row9_col1\" class=\"data row9 col1\" >470.516354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row10\" class=\"row_heading level0 row10\" >1333</th>\n",
       "      <td id=\"T_4854a_row10_col0\" class=\"data row10 col0\" >koki</td>\n",
       "      <td id=\"T_4854a_row10_col1\" class=\"data row10 col1\" >469.324678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row11\" class=\"row_heading level0 row11\" >270</th>\n",
       "      <td id=\"T_4854a_row11_col0\" class=\"data row11 col0\" >militares</td>\n",
       "      <td id=\"T_4854a_row11_col1\" class=\"data row11 col1\" >462.073511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row12\" class=\"row_heading level0 row12\" >1142</th>\n",
       "      <td id=\"T_4854a_row12_col0\" class=\"data row12 col0\" >desmantelan</td>\n",
       "      <td id=\"T_4854a_row12_col1\" class=\"data row12 col1\" >461.474734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row13\" class=\"row_heading level0 row13\" >412</th>\n",
       "      <td id=\"T_4854a_row13_col0\" class=\"data row13 col0\" >cocaina</td>\n",
       "      <td id=\"T_4854a_row13_col1\" class=\"data row13 col1\" >424.029015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row14\" class=\"row_heading level0 row14\" >341</th>\n",
       "      <td id=\"T_4854a_row14_col0\" class=\"data row14 col0\" >frontera</td>\n",
       "      <td id=\"T_4854a_row14_col1\" class=\"data row14 col1\" >423.616447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row15\" class=\"row_heading level0 row15\" >695</th>\n",
       "      <td id=\"T_4854a_row15_col0\" class=\"data row15 col0\" >extradicion</td>\n",
       "      <td id=\"T_4854a_row15_col1\" class=\"data row15 col1\" >418.253149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row16\" class=\"row_heading level0 row16\" >274</th>\n",
       "      <td id=\"T_4854a_row16_col0\" class=\"data row16 col0\" >publica</td>\n",
       "      <td id=\"T_4854a_row16_col1\" class=\"data row16 col1\" >410.108572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row17\" class=\"row_heading level0 row17\" >885</th>\n",
       "      <td id=\"T_4854a_row17_col0\" class=\"data row17 col0\" >aida</td>\n",
       "      <td id=\"T_4854a_row17_col1\" class=\"data row17 col1\" >405.901412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row18\" class=\"row_heading level0 row18\" >5</th>\n",
       "      <td id=\"T_4854a_row18_col0\" class=\"data row18 col0\" >q</td>\n",
       "      <td id=\"T_4854a_row18_col1\" class=\"data row18 col1\" >400.046192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4854a_level0_row19\" class=\"row_heading level0 row19\" >1858</th>\n",
       "      <td id=\"T_4854a_row19_col0\" class=\"data row19 col0\" >impopularidad</td>\n",
       "      <td id=\"T_4854a_row19_col1\" class=\"data row19 col1\" >396.372181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "   <style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_25a61_\" style='display:inline'>\n",
       "  <caption>Feb 19</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >words</th>\n",
       "      <th class=\"col_heading level0 col1\" >retweet_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row0\" class=\"row_heading level0 row0\" >127</th>\n",
       "      <td id=\"T_25a61_row0_col0\" class=\"data row0 col0\" >acabar</td>\n",
       "      <td id=\"T_25a61_row0_col1\" class=\"data row0 col1\" >203.926034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row1\" class=\"row_heading level0 row1\" >133</th>\n",
       "      <td id=\"T_25a61_row1_col0\" class=\"data row1 col0\" >medico</td>\n",
       "      <td id=\"T_25a61_row1_col1\" class=\"data row1 col1\" >189.030391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row2\" class=\"row_heading level0 row2\" >60</th>\n",
       "      <td id=\"T_25a61_row2_col0\" class=\"data row2 col0\" >sistema</td>\n",
       "      <td id=\"T_25a61_row2_col1\" class=\"data row2 col1\" >157.827801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row3\" class=\"row_heading level0 row3\" >235</th>\n",
       "      <td id=\"T_25a61_row3_col0\" class=\"data row3 col0\" >mejores</td>\n",
       "      <td id=\"T_25a61_row3_col1\" class=\"data row3 col1\" >139.925585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row4\" class=\"row_heading level0 row4\" >381</th>\n",
       "      <td id=\"T_25a61_row4_col0\" class=\"data row4 col0\" >banco</td>\n",
       "      <td id=\"T_25a61_row4_col1\" class=\"data row4 col1\" >138.170631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row5\" class=\"row_heading level0 row5\" >348</th>\n",
       "      <td id=\"T_25a61_row5_col0\" class=\"data row5 col0\" >modelo</td>\n",
       "      <td id=\"T_25a61_row5_col1\" class=\"data row5 col1\" >137.586709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row6\" class=\"row_heading level0 row6\" >12</th>\n",
       "      <td id=\"T_25a61_row6_col0\" class=\"data row6 col0\" >salud</td>\n",
       "      <td id=\"T_25a61_row6_col1\" class=\"data row6 col1\" >128.982049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row7\" class=\"row_heading level0 row7\" >13</th>\n",
       "      <td id=\"T_25a61_row7_col0\" class=\"data row7 col0\" >dia</td>\n",
       "      <td id=\"T_25a61_row7_col1\" class=\"data row7 col1\" >124.993642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row8\" class=\"row_heading level0 row8\" >63</th>\n",
       "      <td id=\"T_25a61_row8_col0\" class=\"data row8 col0\" >d</td>\n",
       "      <td id=\"T_25a61_row8_col1\" class=\"data row8 col1\" >122.875973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row9\" class=\"row_heading level0 row9\" >444</th>\n",
       "      <td id=\"T_25a61_row9_col0\" class=\"data row9 col0\" >gaviria</td>\n",
       "      <td id=\"T_25a61_row9_col1\" class=\"data row9 col1\" >120.568406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row10\" class=\"row_heading level0 row10\" >160</th>\n",
       "      <td id=\"T_25a61_row10_col0\" class=\"data row10 col0\" >educacion</td>\n",
       "      <td id=\"T_25a61_row10_col1\" class=\"data row10 col1\" >111.081098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row11\" class=\"row_heading level0 row11\" >3</th>\n",
       "      <td id=\"T_25a61_row11_col0\" class=\"data row11 col0\" >petro</td>\n",
       "      <td id=\"T_25a61_row11_col1\" class=\"data row11 col1\" >105.537268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row12\" class=\"row_heading level0 row12\" >204</th>\n",
       "      <td id=\"T_25a61_row12_col0\" class=\"data row12 col0\" >eps</td>\n",
       "      <td id=\"T_25a61_row12_col1\" class=\"data row12 col1\" >101.905775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row13\" class=\"row_heading level0 row13\" >11</th>\n",
       "      <td id=\"T_25a61_row13_col0\" class=\"data row13 col0\" >bogota</td>\n",
       "      <td id=\"T_25a61_row13_col1\" class=\"data row13 col1\" >101.210206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row14\" class=\"row_heading level0 row14\" >257</th>\n",
       "      <td id=\"T_25a61_row14_col0\" class=\"data row14 col0\" >vandalismo</td>\n",
       "      <td id=\"T_25a61_row14_col1\" class=\"data row14 col1\" >101.082338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row15\" class=\"row_heading level0 row15\" >600</th>\n",
       "      <td id=\"T_25a61_row15_col0\" class=\"data row15 col0\" >drive</td>\n",
       "      <td id=\"T_25a61_row15_col1\" class=\"data row15 col1\" >100.979104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row16\" class=\"row_heading level0 row16\" >592</th>\n",
       "      <td id=\"T_25a61_row16_col0\" class=\"data row16 col0\" >instalado</td>\n",
       "      <td id=\"T_25a61_row16_col1\" class=\"data row16 col1\" >100.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row17\" class=\"row_heading level0 row17\" >620</th>\n",
       "      <td id=\"T_25a61_row17_col0\" class=\"data row17 col0\" >powerpoint</td>\n",
       "      <td id=\"T_25a61_row17_col1\" class=\"data row17 col1\" >90.713529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row18\" class=\"row_heading level0 row18\" >596</th>\n",
       "      <td id=\"T_25a61_row18_col0\" class=\"data row18 col0\" >one</td>\n",
       "      <td id=\"T_25a61_row18_col1\" class=\"data row18 col1\" >90.689104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25a61_level0_row19\" class=\"row_heading level0 row19\" >885</th>\n",
       "      <td id=\"T_25a61_row19_col0\" class=\"data row19 col0\" >reforma</td>\n",
       "      <td id=\"T_25a61_row19_col1\" class=\"data row19 col1\" >88.149883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "   <style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ca817_\" style='display:inline'>\n",
       "  <caption>Feb 20</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >words</th>\n",
       "      <th class=\"col_heading level0 col1\" >retweet_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row0\" class=\"row_heading level0 row0\" >97</th>\n",
       "      <td id=\"T_ca817_row0_col0\" class=\"data row0 col0\" >sistema</td>\n",
       "      <td id=\"T_ca817_row0_col1\" class=\"data row0 col1\" >193.444811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row1\" class=\"row_heading level0 row1\" >38</th>\n",
       "      <td id=\"T_ca817_row1_col0\" class=\"data row1 col0\" >salud</td>\n",
       "      <td id=\"T_ca817_row1_col1\" class=\"data row1 col1\" >193.134346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row2\" class=\"row_heading level0 row2\" >154</th>\n",
       "      <td id=\"T_ca817_row2_col0\" class=\"data row2 col0\" >social</td>\n",
       "      <td id=\"T_ca817_row2_col1\" class=\"data row2 col1\" >158.707458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row3\" class=\"row_heading level0 row3\" >65</th>\n",
       "      <td id=\"T_ca817_row3_col0\" class=\"data row3 col0\" >otoniel</td>\n",
       "      <td id=\"T_ca817_row3_col1\" class=\"data row3 col1\" >156.829158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row4\" class=\"row_heading level0 row4\" >57</th>\n",
       "      <td id=\"T_ca817_row4_col0\" class=\"data row4 col0\" >jepcolombia</td>\n",
       "      <td id=\"T_ca817_row4_col1\" class=\"data row4 col1\" >156.701966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row5\" class=\"row_heading level0 row5\" >1353</th>\n",
       "      <td id=\"T_ca817_row5_col0\" class=\"data row5 col0\" >aspirante</td>\n",
       "      <td id=\"T_ca817_row5_col1\" class=\"data row5 col1\" >150.134003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row6\" class=\"row_heading level0 row6\" >416</th>\n",
       "      <td id=\"T_ca817_row6_col0\" class=\"data row6 col0\" >un</td>\n",
       "      <td id=\"T_ca817_row6_col1\" class=\"data row6 col1\" >141.598045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row7\" class=\"row_heading level0 row7\" >9558</th>\n",
       "      <td id=\"T_ca817_row7_col0\" class=\"data row7 col0\" >yat</td>\n",
       "      <td id=\"T_ca817_row7_col1\" class=\"data row7 col1\" >118.081598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row8\" class=\"row_heading level0 row8\" >4831</th>\n",
       "      <td id=\"T_ca817_row8_col0\" class=\"data row8 col0\" >cocaleros</td>\n",
       "      <td id=\"T_ca817_row8_col1\" class=\"data row8 col1\" >117.815687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row9\" class=\"row_heading level0 row9\" >5742</th>\n",
       "      <td id=\"T_ca817_row9_col0\" class=\"data row9 col0\" >lucilaargiles</td>\n",
       "      <td id=\"T_ca817_row9_col1\" class=\"data row9 col1\" >117.658340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row10\" class=\"row_heading level0 row10\" >11708</th>\n",
       "      <td id=\"T_ca817_row10_col0\" class=\"data row10 col0\" >johannaaguirres</td>\n",
       "      <td id=\"T_ca817_row10_col1\" class=\"data row10 col1\" >116.837714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row11\" class=\"row_heading level0 row11\" >5801</th>\n",
       "      <td id=\"T_ca817_row11_col0\" class=\"data row11 col0\" >pongale</td>\n",
       "      <td id=\"T_ca817_row11_col1\" class=\"data row11 col1\" >116.182252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row12\" class=\"row_heading level0 row12\" >2638</th>\n",
       "      <td id=\"T_ca817_row12_col0\" class=\"data row12 col0\" >cocina</td>\n",
       "      <td id=\"T_ca817_row12_col1\" class=\"data row12 col1\" >116.160733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row13\" class=\"row_heading level0 row13\" >3545</th>\n",
       "      <td id=\"T_ca817_row13_col0\" class=\"data row13 col0\" >chule</td>\n",
       "      <td id=\"T_ca817_row13_col1\" class=\"data row13 col1\" >116.109805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row14\" class=\"row_heading level0 row14\" >6517</th>\n",
       "      <td id=\"T_ca817_row14_col0\" class=\"data row14 col0\" >agradecimiento</td>\n",
       "      <td id=\"T_ca817_row14_col1\" class=\"data row14 col1\" >116.105926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row15\" class=\"row_heading level0 row15\" >7237</th>\n",
       "      <td id=\"T_ca817_row15_col0\" class=\"data row15 col0\" >platajuega</td>\n",
       "      <td id=\"T_ca817_row15_col1\" class=\"data row15 col1\" >116.005366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row16\" class=\"row_heading level0 row16\" >4625</th>\n",
       "      <td id=\"T_ca817_row16_col0\" class=\"data row16 col0\" >fotografo</td>\n",
       "      <td id=\"T_ca817_row16_col1\" class=\"data row16 col1\" >115.930804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row17\" class=\"row_heading level0 row17\" >4884</th>\n",
       "      <td id=\"T_ca817_row17_col0\" class=\"data row17 col0\" >ribace</td>\n",
       "      <td id=\"T_ca817_row17_col1\" class=\"data row17 col1\" >115.892851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row18\" class=\"row_heading level0 row18\" >3821</th>\n",
       "      <td id=\"T_ca817_row18_col0\" class=\"data row18 col0\" >xenofobicas</td>\n",
       "      <td id=\"T_ca817_row18_col1\" class=\"data row18 col1\" >115.879315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca817_level0_row19\" class=\"row_heading level0 row19\" >6845</th>\n",
       "      <td id=\"T_ca817_row19_col0\" class=\"data row19 col0\" >protestantes</td>\n",
       "      <td id=\"T_ca817_row19_col1\" class=\"data row19 col1\" >115.793469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "   <style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ca641_\" style='display:inline'>\n",
       "  <caption>Feb 21</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >words</th>\n",
       "      <th class=\"col_heading level0 col1\" >retweet_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row0\" class=\"row_heading level0 row0\" >306</th>\n",
       "      <td id=\"T_ca641_row0_col0\" class=\"data row0 col0\" >voluntaria</td>\n",
       "      <td id=\"T_ca641_row0_col1\" class=\"data row0 col1\" >1064.036809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row1\" class=\"row_heading level0 row1\" >214</th>\n",
       "      <td id=\"T_ca641_row1_col0\" class=\"data row1 col0\" >interrupcion</td>\n",
       "      <td id=\"T_ca641_row1_col1\" class=\"data row1 col1\" >1045.956901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row2\" class=\"row_heading level0 row2\" >5</th>\n",
       "      <td id=\"T_ca641_row2_col0\" class=\"data row2 col0\" >semana</td>\n",
       "      <td id=\"T_ca641_row2_col1\" class=\"data row2 col1\" >1022.165659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row3\" class=\"row_heading level0 row3\" >360</th>\n",
       "      <td id=\"T_ca641_row3_col0\" class=\"data row3 col0\" >codigo</td>\n",
       "      <td id=\"T_ca641_row3_col1\" class=\"data row3 col1\" >1019.773222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row4\" class=\"row_heading level0 row4\" >53</th>\n",
       "      <td id=\"T_ca641_row4_col0\" class=\"data row4 col0\" >delito</td>\n",
       "      <td id=\"T_ca641_row4_col1\" class=\"data row4 col1\" >937.606945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row5\" class=\"row_heading level0 row5\" >188</th>\n",
       "      <td id=\"T_ca641_row5_col0\" class=\"data row5 col0\" >logra</td>\n",
       "      <td id=\"T_ca641_row5_col1\" class=\"data row5 col1\" >903.136082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row6\" class=\"row_heading level0 row6\" >269</th>\n",
       "      <td id=\"T_ca641_row6_col0\" class=\"data row6 col0\" >penal</td>\n",
       "      <td id=\"T_ca641_row6_col1\" class=\"data row6 col1\" >863.983316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row7\" class=\"row_heading level0 row7\" >47</th>\n",
       "      <td id=\"T_ca641_row7_col0\" class=\"data row7 col0\" >avance</td>\n",
       "      <td id=\"T_ca641_row7_col1\" class=\"data row7 col1\" >834.511872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row8\" class=\"row_heading level0 row8\" >80</th>\n",
       "      <td id=\"T_ca641_row8_col0\" class=\"data row8 col0\" >fallo</td>\n",
       "      <td id=\"T_ca641_row8_col1\" class=\"data row8 col1\" >677.793422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row9\" class=\"row_heading level0 row9\" >767</th>\n",
       "      <td id=\"T_ca641_row9_col0\" class=\"data row9 col0\" >elimina</td>\n",
       "      <td id=\"T_ca641_row9_col1\" class=\"data row9 col1\" >663.738387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row10\" class=\"row_heading level0 row10\" >146</th>\n",
       "      <td id=\"T_ca641_row10_col0\" class=\"data row10 col0\" >primeras</td>\n",
       "      <td id=\"T_ca641_row10_col1\" class=\"data row10 col1\" >661.836157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row11\" class=\"row_heading level0 row11\" >16</th>\n",
       "      <td id=\"T_ca641_row11_col0\" class=\"data row11 col0\" >historico</td>\n",
       "      <td id=\"T_ca641_row11_col1\" class=\"data row11 col1\" >654.652373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row12\" class=\"row_heading level0 row12\" >408</th>\n",
       "      <td id=\"T_ca641_row12_col0\" class=\"data row12 col0\" >latinoamericano</td>\n",
       "      <td id=\"T_ca641_row12_col1\" class=\"data row12 col1\" >641.669070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row13\" class=\"row_heading level0 row13\" >247</th>\n",
       "      <td id=\"T_ca641_row13_col0\" class=\"data row13 col0\" >violacion</td>\n",
       "      <td id=\"T_ca641_row13_col1\" class=\"data row13 col1\" >625.994875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row14\" class=\"row_heading level0 row14\" >27</th>\n",
       "      <td id=\"T_ca641_row14_col0\" class=\"data row14 col0\" >embarazo</td>\n",
       "      <td id=\"T_ca641_row14_col1\" class=\"data row14 col1\" >615.007819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row15\" class=\"row_heading level0 row15\" >110</th>\n",
       "      <td id=\"T_ca641_row15_col0\" class=\"data row15 col0\" >latina</td>\n",
       "      <td id=\"T_ca641_row15_col1\" class=\"data row15 col1\" >581.127159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row16\" class=\"row_heading level0 row16\" >49</th>\n",
       "      <td id=\"T_ca641_row16_col0\" class=\"data row16 col0\" >causajustaco</td>\n",
       "      <td id=\"T_ca641_row16_col1\" class=\"data row16 col1\" >580.155154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row17\" class=\"row_heading level0 row17\" >216</th>\n",
       "      <td id=\"T_ca641_row17_col0\" class=\"data row17 col0\" >feto</td>\n",
       "      <td id=\"T_ca641_row17_col1\" class=\"data row17 col1\" >568.448209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row18\" class=\"row_heading level0 row18\" >533</th>\n",
       "      <td id=\"T_ca641_row18_col0\" class=\"data row18 col0\" >malformacion</td>\n",
       "      <td id=\"T_ca641_row18_col1\" class=\"data row18 col1\" >561.760247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca641_level0_row19\" class=\"row_heading level0 row19\" >46</th>\n",
       "      <td id=\"T_ca641_row19_col0\" class=\"data row19 col0\" >abortar</td>\n",
       "      <td id=\"T_ca641_row19_col1\" class=\"data row19 col1\" >558.493116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_side_by_side(top10df, [f'Feb {15 + i}' for i in range(7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1740330",
   "metadata": {},
   "source": [
    "Lo cual es bastante impresionante a pesar de ser un método de ser basado exclusivamente de conteo de palabras.\n",
    "\n",
    "Por ejemplo concentremosnos en el 21 febrero, día en el que se dio a conocer la controversial noticia de la despenalización del aborto en Colombia.\n",
    "\n",
    "Podemos ver que las palabras con mayor retweets son muy relacionadas a la tendencia del día, como embarazo, aborto, feto, malformación, interrupción, voluntaria entre otras.\n",
    "\n",
    "Un análisis similar se podría realizar para los otros días según sus tendencias, pero el ejemplo del 21 de febrero se puede evidenciar claramente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ebd95",
   "metadata": {},
   "source": [
    "## Calculadora de Retweets\n",
    "Ahora podemos ver la calculadora en acción con una interfaz gráfica amigable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4881348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7862/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x21fc8ff1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x21f9bd41eb0>,\n",
       " 'http://127.0.0.1:7862/',\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculator(DayOfWeek, Tweet):\n",
    "    if DayOfWeek == \"Feb15\":\n",
    "        return float(regr0.predict(getNewTweetVector(model0, Tweet).reshape(1,-1))[0])\n",
    "    elif DayOfWeek == \"Feb16\":\n",
    "        return float(regr1.predict(getNewTweetVector(model1, Tweet).reshape(1,-1))[0])\n",
    "    elif DayOfWeek == \"Feb17\":\n",
    "        return float(regr2.predict(getNewTweetVector(model2, Tweet).reshape(1,-1))[0])\n",
    "    elif DayOfWeek == \"Feb18\":\n",
    "        return float(regr3.predict(getNewTweetVector(model3, Tweet).reshape(1,-1))[0])\n",
    "    elif DayOfWeek == \"Feb19\":\n",
    "        return float(regr4.predict(getNewTweetVector(model4, Tweet).reshape(1,-1))[0])\n",
    "    elif DayOfWeek == \"Feb20\":\n",
    "        return float(regr5.predict(getNewTweetVector(model5, Tweet).reshape(1,-1))[0])\n",
    "    elif DayOfWeek == \"Feb21\":\n",
    "        return float(regr6.predict(getNewTweetVector(model6, Tweet).reshape(1,-1))[0])\n",
    "\n",
    "iface = gr.Interface(\n",
    "    calculator,\n",
    "    [gr.inputs.Radio([\"Feb15\", \"Feb16\", \"Feb17\", \"Feb18\", \"Feb19\", \"Feb20\", \"Feb21\"]), \"text\"],\n",
    "    \"number\",\n",
    "    title=\"ReTweet Calculator\",\n",
    "    description=\"Introduzca un tweet y seleccione un día, la calculadora predecirá los retweets del tweet ingresado si se hubiese publicado en un día de la semana.\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d3ec0",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "De este trabajo podemos concluir:\n",
    "\n",
    "- El procesamiento de lenguaje natural tiene muchas aplicaciones, y este es un ejemplo de cómo lo podemos aplicar a analizar tendencias, tópicos de cosas del día a día.\n",
    "\n",
    "- Podemos ver como al mezclar conceptos tan básicos como conteos y frecuencias, es posible realizar un análisis de tópicos de un conjunto de datos, con ayuda de herramientas como la descomposición SVD. Sin realmente entrar a detallar estos tópicos y sin ir a leer 100 mil tweets, es posible resumir las tendencias en unos tópicos.\n",
    "\n",
    "- Las aplicaciones de Word2Vec son increíbles y fascinantes, el concepto de embeber algo tan natural como palabras, a un espacio tan matemático de $\\mathbb{R}^{n}$ es algo que funciona muy bien y tiene demasiadas aplicaciones.\n",
    "\n",
    "- Las puertas que nos abre Word2Vec son todas las aplicaciones de aprendizaje automático de máquina, como lo vimos en este caso, con un regresor de Random Forest. Con este se pudo alcanzar a realizar predicciones decentes y ayudarnos a analizar aún más que palabras producen retweets, asimismo predecir cuantos retweets tendrá un tweet antes de publicarlo, acercándonos más a las tendencias.\n",
    "\n",
    "- Los resultados obtenidos son acorde a la realidad, en esta última semana ha habido bastante movida sobre el aborto y bastante movimiento político dada las elecciones de senado que se acercan en Colombia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adebfef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.211074589074458"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr0.predict(getNewTweetVector(model0, \"sample tweet\").reshape(1,-1))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
