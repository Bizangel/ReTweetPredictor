{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63940cb-63c4-4311-96b5-bee0bbad05c0",
   "metadata": {},
   "source": [
    "# Proyecto 1 de Introducción al Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc36ad-c8f9-4a63-8a3f-4220ffd2742d",
   "metadata": {},
   "source": [
    "Para este proyecto deberan realizar web scrapping, usando la API de Tweeter (v2). Esta API nos permite recolectar tweets con diversas configuraciones y parámetros, búsquedas con filtros, etc. Además nos permite sectorizar, definir el lugar, los tiempos, entre otros.\n",
    "\n",
    "Para usar con todo el potencial esta API necesitamos una cuenta premium o académica. Sin embargo, este proyecto tan sólo necesita una cuenta *essential* (si quieren usar más información, más detallada, lo podemos mirar). La mayor limitante es que trabajaremos sobre la última semana. \n",
    "\n",
    "Es importante que lean y apliquen el notebook `Twitter_API_v2_Guide_essential.ipynb`, el cual explica de forma sencilla como usar la API (lo he modificado para la cuenta essential y con alguna configuración particular). \n",
    "\n",
    "Cada proyecto tendrá las siguentes partes:\n",
    "\n",
    "1. **Obtención de los datos mediante la API**\n",
    "2. **Preprocesamiento del texto**: tokenización (recomiendo usar `nltk.tokenize.TweetTokenizer`), lematización, filtrado de stop words etc. En este punto hay que tener cuidado, porque trabajaremos en el idioma español y tienen una configuración especial al ser tweets (recomiendo ver [este blog](https://jairoandres.com/spacy-procesando-tweets/)).\n",
    "3. **Análisis de tópicos**: con el dataset obtenido, deberán analizar cuales son los temas principales a partir de una matriz término-documento y de su respectiva factorización matricial (SVD, NFM, PCA). Esto por ejemplo, podría indicar algunas tendencias diarias, o durante la última semana.\n",
    "4. **Word2vec y similares**: se deberá entrenar modelos de word2vec para tener una representación vectorial de las palabras y posteriormente poderlas analizar y/o crear modelos de machine learning.\n",
    "5. **Interfaz gráfica**: Gradio es un framework increíblemente sencillo para realizar interfaces super sencillas y llevar los modelos a producción. No les pediré en este proyecto llevarlo a un servidor (que hoy en día es super sencillo), pero si al menos realizar una sencilla interfaz gráfica sobre el notebook de jupyter. Recomiendo que lean este [tutorial de Gradio](https://gradio.app/getting_started/).\n",
    "\n",
    "Además de los cinco pasos anteriores, es importante que realicen gráficos y visualizaciones que ayuden a la interpretación. No olviden ir analizando y comentando los hallazgos, y sobretodo **concluir**. El entregable es un notebook de Jupyter, debidamente presentado y comentado.\n",
    "\n",
    "Debe también realizar un pequeño video promocional de la aplicación (de una duración máxima de tres minutos, no tiene que explicar en detalle el funcionamiento, sino vender el producto)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29d3bf-ac00-46a0-9f18-5c6a74100a3a",
   "metadata": {},
   "source": [
    "## Proyecto A - Sinónimos y Antónimos\n",
    "Deberá construir un dataset con la mayor cantidad de tweets en español que pueda (con las limitaciones de la cuenta essential) y construir un diccionario de sinónimos y antónimos con base en la similitud entre los vectores de palabras, de un modelo word2vec. Pruebe diferentes configuraciones del modelo (es decir, modelos skip-gram, CBOW, de diferente tamaño de ventana, diferente tamaño del vector, etc), y observe cuál funciona mejor. El diccionario se sinónimos y antónimos debe mostrarse en una interfaz de usuario sencilla. La aplicación debe producir al menos un sinónimo y un antónimo por la palabra escrita.\n",
    "\n",
    "También, deben analizar tópicos mediante factorización de matrices de término-documento, y realizando un clustering sobre los vectores de palabra word2vec (recomiendo GMM) para identificar patrones o tendencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f3f74-97b3-454a-b6d5-93d713637c72",
   "metadata": {},
   "source": [
    "## Proyecto B: Calculadora de ReTweets\n",
    "Deberá construir un dataset con la mayor cantidad posible de tweets en españól que pueda, pero limitado sólo a Colombia, durante la última semana (use en el keyword la palabra Colombia o el operador `entity:Colombia`). Realice un análisis de tópicos para inferir las posibles tendencias durante la última semana en Colombia.\n",
    "\n",
    "Para cada día de tweets extraído realice una aplicación que sea capaz de predecir el número de retweets (RTs) que van a realizar ese día. Use la mejor configuración del modelo word2vec dentro de varias (skip-gram, CBOW, diferentes anchos de ventana, tamaño del vector, etc). Este es un problema de regresión. ¿Puede inferir de alguna forma cuales son las palabras que más likes producen durante el día? (puede ser más fácil hacerlo con matriz documento-término)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980c8dc-47b2-4845-a6c6-31977deacad9",
   "metadata": {},
   "source": [
    "## Proyecto C: Análisis de sentimientos\n",
    "\n",
    "Para construir un buen análisis de sentimientos necesitamos que cada documento (en este caso tweet) este bien etiquetado de acuerdo a la emoción. Pero, para limitar el alcance del trabajo, usaremos el siguiente truco: recolecte la mayor cantidad de tweets en español que pueda (limitado por la cuenta essential) pero realizando varias consultas, una con emoticones que indiquen Felicidad, otra consulta con emoticones que indiquen tristeza y otra con emoticones que indiquen Rabia. Una vez realizado esto, elimine del texto los emoticones (de lo contrario ya sabríamos que emoción es). Con este dataset debe realizar un clasificador de las tres emociones usando, matrices de co-ocurrencia (término-documento), word2vec (skip-gram y/o CBOW) y un modelo denominado doc2vec (ver este [link](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py)).  \n",
    "\n",
    "No olvide realizar también un análisis por tópicos con las matrices de co-ocurrencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
